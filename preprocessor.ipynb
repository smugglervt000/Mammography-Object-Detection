{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import ast\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.io import imread\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EMBED_ROOT = Path(\"/vol/biomedic3/data/EMBED\")\n",
    "VINDR_ROOT = Path(\"/vol/biomedic3/data/VinDR-Mammo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following merged_dfcsv file can be recreated by running the merger_scripy.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom = pd.read_csv(\"csv_files/merged_df.csv\", low_memory=False)\n",
    "\n",
    "vindr_findings = pd.read_csv(\n",
    "    VINDR_ROOT / \"finding_annotations.csv\", low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3471067/3027192612.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  view_nan[\"ViewPosition\"] = view_nan[\"SeriesDescription\"].apply(\n"
     ]
    }
   ],
   "source": [
    "# XCCL shouldn't be converted to CC so manually editing it\n",
    "dicom.loc[\n",
    "    (dicom[\"SeriesDescription\"] == \"RXCCL\") | (dicom[\"SeriesDescription\"] == \"LXCCL\"),\n",
    "    \"ViewPosition\",\n",
    "] = \"XCCL\"\n",
    "\n",
    "# Getting all rows with \"ViewPosition\" == Nan (but for which SeriesDescription is also not nan, as these are the ones subject to the data entry error)\n",
    "view_nan = dicom.loc[\n",
    "    (dicom.ViewPosition.isna()) & (dicom.SeriesDescription.isna() == False)\n",
    "]\n",
    "\n",
    "# Drop these rows from\n",
    "dicom_no_nans = dicom[~dicom.index.isin(view_nan.index)]\n",
    "\n",
    "view_nan[\"ViewPosition\"] = view_nan[\"SeriesDescription\"].apply(\n",
    "    lambda x: \"CC\" if \"CC\" in x else (\"MLO\" if \"MLO\" in x else None)\n",
    ")\n",
    "\n",
    "dicom = pd.concat([dicom_no_nans, view_nan], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508846\n",
      "311738\n"
     ]
    }
   ],
   "source": [
    "print(len(dicom))\n",
    "# Remove any duplicated images\n",
    "dicom = dicom.drop_duplicates(subset=\"anon_dicom_path\")\n",
    "# Remove spot compressed and magnified images\n",
    "dicom = dicom[dicom.spot_mag.isna()]\n",
    "# Remove invalid views\n",
    "dicom = dicom[dicom.ViewPosition.isin([\"CC\", \"MLO\"])]\n",
    "dicom = dicom[dicom.FinalImageType.isin([\"2D\"])]\n",
    "# Remove images from male clients\n",
    "dicom = dicom[dicom.PatientSex == \"F\"]\n",
    "print(len(dicom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any unnecessary fields from the DICOM imagewise dataframe (this may need to be updated in the future if other fields are deemed relevant)\n",
    "dicom = dicom[\n",
    "    [\n",
    "        \"empi_anon\",\n",
    "        \"acc_anon\",\n",
    "        \"image_path\",\n",
    "        \"ViewPosition\",\n",
    "        \"Manufacturer\",\n",
    "        \"ManufacturerModelName\",\n",
    "        'ROI_coords',\n",
    "        'num_roi',\n",
    "        'PatientOrientation',\n",
    "        'Rows',\n",
    "        'Columns',\n",
    "        'tissueden',\n",
    "        'massshape',\n",
    "        'path_severity',\n",
    "        'asses',\n",
    "        'side',\n",
    "        'massmargin', \n",
    "        'massdens', \n",
    "        'calcfind',\n",
    "        'calcdistri', \n",
    "        'calcnumber', \n",
    "        'otherfind', \n",
    "        'implanfind', \n",
    "        'numfind', \n",
    "    ]\n",
    "]\n",
    "\n",
    "vindr_findings = vindr_findings[\n",
    "    [\n",
    "        'study_id',\n",
    "        'series_id',\n",
    "        'image_id',\n",
    "        'height',\n",
    "        'width',\n",
    "        'breast_birads',\n",
    "        'breast_density',\n",
    "        'finding_categories',\n",
    "        'finding_birads',\n",
    "        'xmin',\n",
    "        'ymin',\n",
    "        'xmax',\n",
    "        'ymax'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breast_birads\n",
       "BI-RADS 1    13406\n",
       "BI-RADS 2     4676\n",
       "BI-RADS 4     1005\n",
       "BI-RADS 3      972\n",
       "BI-RADS 5      427\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindr_findings['breast_birads'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breast_density\n",
       "DENSITY C    15695\n",
       "DENSITY D     2717\n",
       "DENSITY B     1973\n",
       "DENSITY A      101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindr_findings['breast_density'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finding_categories\n",
       "['No Finding']                                                                                      18232\n",
       "['Mass']                                                                                             1123\n",
       "['Suspicious Calcification']                                                                          402\n",
       "['Focal Asymmetry']                                                                                   232\n",
       "['Architectural Distortion']                                                                           95\n",
       "['Asymmetry']                                                                                          90\n",
       "['Suspicious Calcification', 'Mass']                                                                   82\n",
       "['Suspicious Lymph Node']                                                                              57\n",
       "['Skin Thickening']                                                                                    38\n",
       "['Suspicious Calcification', 'Focal Asymmetry']                                                        31\n",
       "['Global Asymmetry']                                                                                   24\n",
       "['Suspicious Calcification', 'Architectural Distortion']                                               13\n",
       "['Nipple Retraction']                                                                                  12\n",
       "['Skin Retraction']                                                                                     7\n",
       "['Skin Thickening', 'Nipple Retraction']                                                                6\n",
       "['Suspicious Calcification', 'Architectural Distortion', 'Mass']                                        4\n",
       "['Suspicious Calcification', 'Nipple Retraction', 'Mass']                                               4\n",
       "['Skin Thickening', 'Focal Asymmetry']                                                                  4\n",
       "['Nipple Retraction', 'Mass']                                                                           3\n",
       "['Suspicious Calcification', 'Asymmetry']                                                               3\n",
       "['Skin Retraction', 'Skin Thickening']                                                                  3\n",
       "['Skin Retraction', 'Nipple Retraction', 'Mass']                                                        3\n",
       "['Suspicious Calcification', 'Architectural Distortion', 'Nipple Retraction', 'Skin Retraction']        2\n",
       "['Skin Thickening', 'Global Asymmetry', 'Nipple Retraction']                                            2\n",
       "['Architectural Distortion', 'Mass']                                                                    2\n",
       "['Skin Retraction', 'Nipple Retraction']                                                                2\n",
       "['Nipple Retraction', 'Skin Thickening', 'Mass']                                                        2\n",
       "['Architectural Distortion', 'Asymmetry']                                                               1\n",
       "['Nipple Retraction', 'Asymmetry']                                                                      1\n",
       "['Skin Thickening', 'Mass']                                                                             1\n",
       "['Asymmetry', 'Mass']                                                                                   1\n",
       "['Skin Retraction', 'Architectural Distortion', 'Suspicious Calcification']                             1\n",
       "['Suspicious Calcification', 'Architectural Distortion', 'Focal Asymmetry']                             1\n",
       "['Focal Asymmetry', 'Mass']                                                                             1\n",
       "['Skin Thickening', 'Asymmetry']                                                                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK BOUNDING BOX COUNTS\n",
    "vindr_findings['finding_categories'].unique()\n",
    "# Probably want to check if theres better ways to combine these since theyre quite repetitive\n",
    "vindr_cat_counts = vindr_findings['finding_categories'].value_counts()\n",
    "vindr_cat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this for multi-class filtering\n",
    "def assign_label(finding_categories):\n",
    "    if finding_categories == \"['No Finding']\":\n",
    "        return 5\n",
    "    elif finding_categories == \"['Mass']\":\n",
    "        return 0\n",
    "    elif finding_categories == \"['Suspicious Calcification']\":\n",
    "        return 1\n",
    "    elif finding_categories == \"['Asymmetry']\":\n",
    "        return 2\n",
    "    elif finding_categories == \"['Architectural Distortion']\":\n",
    "        return 3\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "vindr_findings['label'] = vindr_findings['finding_categories'].apply(assign_label)\n",
    "\n",
    "vindr_findings = vindr_findings.dropna(subset='label')\n",
    "vindr_findings['label'] = vindr_findings['label'].astype(int)\n",
    "vindr_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'finding_categories' column from string representation of list to actual list\n",
    "vindr_findings['finding_categories'] = vindr_findings['finding_categories'].apply(eval)\n",
    "\n",
    "# Combine 'xmin', 'ymin', 'xmax', 'ymax' \n",
    "vindr_findings['bbox'] = vindr_findings.apply(\n",
    "    lambda row: [row['ymin'], row['xmin'], row['ymax'], row['xmax']] if pd.notnull(row[['xmin', 'ymin', 'xmax', 'ymax']]).any() else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop the individual columns 'xmin', 'ymin', 'xmax', 'ymax'\n",
    "vindr_findings.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to filter VinDr by Mass category, otherwise uncomment the last line to proceed with unfiltered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all bounding boxes that don't bound a mass\n",
    "def contains_mass_or_suspicious_calcification(category_list):\n",
    "    return 'Mass' in category_list \n",
    "\n",
    "def filter_finding_categories(df):\n",
    "    #Remove unnecessary categories\n",
    "    df = df[(df['finding_categories'].apply(contains_mass_or_suspicious_calcification)) | (df['finding_categories'].apply(lambda x: x == ['No Finding']))]\n",
    "    #Remove findings with birads recorded as None\n",
    "    df = df[(df['finding_birads'].notna()) | (df['finding_categories'].apply(lambda x: x == ['No Finding']))]\n",
    "    return df\n",
    "\n",
    "filtered_vindr = filter_finding_categories(vindr_findings)\n",
    "# filtered_vindr = vindr_findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = filtered_vindr[filtered_vindr.duplicated(subset=['study_id', 'image_id'], keep=False)]\n",
    "\n",
    "# Function to aggregate the relevant columns\n",
    "def aggregate_columns(group):\n",
    "    agg_dict = {}\n",
    "    for col in ['finding_categories', 'finding_birads']:\n",
    "        agg_dict[col] = group[col].apply(lambda x: [x] if not isinstance(x, list) else x).sum()\n",
    "    # For 'bbox', ensure it is a list of lists\n",
    "    agg_dict['bbox'] = group['bbox'].apply(lambda x: [x] if not isinstance(x, list) else x).tolist()\n",
    "    # Uncomment the following line if using multi-class labeling\n",
    "    # agg_dict['label'] = group['label'].apply(lambda x: x).tolist()\n",
    "\n",
    "    # Include all other columns, taking the first value \n",
    "    for col in group.columns:\n",
    "        if col not in agg_dict and col not in ['study_id', 'image_id']:\n",
    "            agg_dict[col] = group[col].iloc[0]\n",
    "    agg_dict['image_path'] = group['study_id'].iloc[0] + '/' + group['image_id'].iloc[0] + '.png'\n",
    "    return pd.Series(agg_dict)\n",
    "\n",
    "# Group duplicate rows by 'study_id' and 'image_id' and apply the aggregation function\n",
    "collapsed_duplicates = duplicate_rows.groupby(['study_id', 'image_id']).apply(aggregate_columns).reset_index(drop=True)\n",
    "\n",
    "# Find non-duplicate rows\n",
    "non_duplicate_rows = filtered_vindr[~filtered_vindr.duplicated(subset=['study_id', 'image_id'], keep=False)].copy()\n",
    "\n",
    "# Add 'image_path' to non-duplicate rows \n",
    "non_duplicate_rows.loc[:, 'image_path'] = non_duplicate_rows.apply(lambda row: row['study_id'] + '/' + row['image_id'] + '.png', axis=1)\n",
    "\n",
    "# Remove 'study_id' and 'image_id' columns \n",
    "non_duplicate_rows = non_duplicate_rows.drop(columns=['study_id', 'image_id'])\n",
    "\n",
    "# Combine collapsed duplicates with non-duplicate rows\n",
    "vindr_final = pd.concat([collapsed_duplicates, non_duplicate_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3471067/2371499883.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace({\"tissueden\": dens_conversion}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Conversion dictionary to standardised naming of various fields in clincial metadata\n",
    "\n",
    "# Human reader BIRADS density assessment\n",
    "dens_conversion = {1.0: \"A\", 2.0: \"B\", 3.0: \"C\", 4.0: \"D\"}\n",
    "\n",
    "# Remove cases from cases a valid BIRADS density assessment\n",
    "df = dicom[dicom.tissueden.isin([1.0, 2.0, 3.0, 4.0])]\n",
    "df.replace({\"tissueden\": dens_conversion}, inplace=True)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asses\n",
       "N    205509\n",
       "B     31547\n",
       "A     26027\n",
       "P      8658\n",
       "S      2315\n",
       "K       650\n",
       "M       256\n",
       "X        17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['asses'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tissueden\n",
       "B    117304\n",
       "C    111797\n",
       "A     31697\n",
       "D     14181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tissueden'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3471067/1809121448.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_limited['mass_finding'] = df_limited['massshape'].isin(['G', 'R', 'O', 'X', 'N', 'Y', 'D', 'L']) | (df_limited['massmargin'].isin(['D', 'U', 'M', 'I', 'S'])) | (df_limited['massdens'].isin(['+', '-', '='])).astype(int)\n",
      "/tmp/ipykernel_3471067/1809121448.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_limited['assy_finding'] = df_limited['massshape'].isin(['T', 'B', 'S', 'F', 'V']).astype(int)\n",
      "/tmp/ipykernel_3471067/1809121448.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_limited['arch_distortion_finding'] = df_limited['massshape'].isin(['Q', 'A']).astype(int)\n",
      "/tmp/ipykernel_3471067/1809121448.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_limited['calcdistri'] = ((~df_limited['calcdistri'].isna()) | (~df_limited['calcfind'].isna()) | (df_limited['calcnumber'] != 0)).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Logic implemented from https://github.com/Emory-HITI/EMBED_Open_Data/blob/main/Sample_Notebook.ipynb\n",
    "# These variables are binary tags saying whether the finding is mass, asymetry, arch distortion or calcification\n",
    "df_limited = df.loc[df.num_roi > 0]\n",
    "\n",
    "df_limited['mass_finding'] = df_limited['massshape'].isin(['G', 'R', 'O', 'X', 'N', 'Y', 'D', 'L']) | (df_limited['massmargin'].isin(['D', 'U', 'M', 'I', 'S'])) | (df_limited['massdens'].isin(['+', '-', '='])).astype(int)\n",
    "df_limited['assy_finding'] = df_limited['massshape'].isin(['T', 'B', 'S', 'F', 'V']).astype(int)\n",
    "df_limited['arch_distortion_finding'] = df_limited['massshape'].isin(['Q', 'A']).astype(int)\n",
    "df_limited['calcdistri'] = ((~df_limited['calcdistri'].isna()) | (~df_limited['calcfind'].isna()) | (df_limited['calcnumber'] != 0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "massshape\n",
       "F            1318\n",
       "S             945\n",
       "O             400\n",
       "Q             243\n",
       "G             117\n",
       "R              49\n",
       "A              26\n",
       "Y              21\n",
       "X              18\n",
       "V              10\n",
       "T               4\n",
       "B               2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the sum across the specified columns for each row\n",
    "df_limited[['massshape']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3471067/1046065833.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_limited['total_findingsinfo_perrow'] = df_limited[['mass_finding', 'assy_finding', 'arch_distortion_finding', 'calcdistri']].sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_findingsinfo_perrow\n",
       "1                            4018\n",
       "0                             823\n",
       "2                             133\n",
       "3                               3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limited['total_findingsinfo_perrow'] = df_limited[['mass_finding', 'assy_finding', 'arch_distortion_finding', 'calcdistri']].sum(axis=1)\n",
    "# How many images without any finding description?\n",
    "df_limited[['total_findingsinfo_perrow']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>num_roi</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_findingsinfo_perrow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>776</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3623</td>\n",
       "      <td>359</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "num_roi                       1    2   3  4\n",
       "total_findingsinfo_perrow                  \n",
       "0                           776   41   6  0\n",
       "1                          3623  359  36  0\n",
       "2                           118   14   0  1\n",
       "3                             3    0   0  0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_limited['total_findingsinfo_perrow'], df_limited['num_roi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY FILTERING TO EMBED DATA\n",
    "\n",
    "df_limited = df_limited[df_limited['mass_finding'] > 0]\n",
    "\n",
    "# Put embed data back together\n",
    "df_no_roi = df.loc[df.num_roi == 0]\n",
    "df = pd.concat([df_no_roi, df_limited])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency \n",
    "\n",
    "vindr_final['numfind'] = vindr_final['bbox'].apply(lambda x: len(x) if x is not None else 0)\n",
    "\n",
    "vindr_final['patient_id'] = vindr_final['series_id']\n",
    "vindr_final = vindr_final.drop(columns=['series_id'])\n",
    "\n",
    "df = df.drop(columns=['numfind'])\n",
    "df['numfind'] = df['num_roi']\n",
    "df = df.drop(columns=['num_roi'])\n",
    "\n",
    "df['patient_id'] = df['empi_anon']\n",
    "df = df.drop(columns=['empi_anon'])\n",
    "\n",
    "df['height'] = df['Rows']\n",
    "df['width'] = df['Columns']\n",
    "df['bbox'] = df['ROI_coords']\n",
    "df = df.drop(columns=['Rows', 'Columns', 'ROI_coords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell for multi-class labeling\n",
    "\n",
    "# Assuming 'mass_finding', 'calcdistri', 'assy_finding', and 'arch_distortion_finding' are the columns in your dataframe\n",
    "conditions = [\n",
    "    df['mass_finding'] > 0,\n",
    "    df['calcdistri'] > 0,\n",
    "    df['assy_finding'] > 0,\n",
    "    df['arch_distortion_finding'] > 0\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2, 3]\n",
    "\n",
    "df['label'] = np.select(conditions, choices, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment label for multi-class\n",
    "\n",
    "df = df[\n",
    "    [\n",
    "        'image_path',\n",
    "        'patient_id',\n",
    "        'height',\n",
    "        'width',\n",
    "        'bbox',\n",
    "        'numfind',\n",
    "        # 'label'\n",
    "    ]\n",
    "]\n",
    "\n",
    "vindr_final = vindr_final[\n",
    "    [\n",
    "        'image_path',\n",
    "        'patient_id',\n",
    "        'height',\n",
    "        'width',\n",
    "        'bbox',\n",
    "        'numfind',\n",
    "        # 'label'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for rescaling bounding box coordinates to 1024x768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_flip_bounding_box(orig_coords, orig_height, orig_width, new_height=1024, new_width=768, flip_horizontal = False, flip_vertical = False):\n",
    "    \"\"\"\n",
    "    Transform bounding box coords to fit on the rescaled DICOM image. \n",
    "\n",
    "    Bounding box outputs are returned in form [y1, x1, y2, x2], where [y1, x1] is at the top left\n",
    "    (ie y1 < y2, and x1 < x2) of image.\n",
    "\n",
    "    \"\"\"\n",
    "    height_decrease = new_height / orig_height\n",
    "    width_decrease = new_width / orig_width\n",
    "\n",
    "    scale_factor = min(height_decrease, width_decrease)\n",
    "\n",
    "    # Rescale the box to be relative to full size image.\n",
    "    coords = (orig_coords * scale_factor).astype(\"int\").tolist()\n",
    "    y1, x1, y2, x2 = coords\n",
    "    # Reflect bbox co-ords based on horizontal or vertical flipping from original patient orientation\n",
    "    # (Remember indexing starts from 0, so subtract 1 from geometric lengths).\n",
    "    # Assume output transformation co-ords identical to original, and apply each separately\n",
    "    y1_new, x1_new, y2_new, x2_new = coords\n",
    "    # Single reflection will yield (y1 > y2) & (x1 > x2), scale by bbox width to get top-left and bottom-right coords\n",
    "    bbox_width = abs(x2 - x1)\n",
    "    if flip_horizontal:\n",
    "        x1_new = new_width - 1 - x1 - bbox_width\n",
    "        x2_new = new_width - 1 - x2 + bbox_width\n",
    "    if flip_vertical:\n",
    "        y1_new = new_height - 1 - y1 - bbox_width\n",
    "        y2_new = new_height - 1 - y2 + bbox_width\n",
    "\n",
    "    # Convert to bbox format xywh\n",
    "    # y0, x0 = y1_new, x1_new\n",
    "    # width = x2_new - x1_new\n",
    "    # height = y2_new - y1_new\n",
    "\n",
    "    return x1_new, y1_new, x2_new, y2_new\n",
    "\n",
    "def convert_str_bbox_to_numpy(coords, embed):\n",
    "    if embed:\n",
    "        return np.array(ast.literal_eval(coords.replace('(', '[').replace(')', ']').replace(' ','')))\n",
    "    else:\n",
    "        return np.array(ast.literal_eval(coords.replace(' ','')))\n",
    "\n",
    "def process_bboxes(bbox_str, image_height, image_width, embed=True):\n",
    "    bboxes = convert_str_bbox_to_numpy(bbox_str, embed)\n",
    "    processed_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2 = scale_and_flip_bounding_box(bbox, image_height, image_width)\n",
    "        processed_bboxes.append([x1, y1, x2, y2])\n",
    "    return processed_bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_finds = df[df['numfind'] > 0]\n",
    "df_no_finds = df[df['numfind'] == 0]\n",
    "vindr_with_finds = vindr_final[vindr_final['numfind'] > 0]\n",
    "vindr_no_finds = vindr_final[vindr_final['numfind'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label back in for multi-class\n",
    "\n",
    "embdata_df = pd.DataFrame(columns=['image_path', 'patient_id', 'numfind', 'bbox', 'height', 'width']) #, 'label'])\n",
    "vindr_df = pd.DataFrame(columns=['image_path', 'patient_id', 'numfind', 'bbox', 'height', 'width']) #, 'label'])\n",
    "\n",
    "for _, row in df_with_finds.iterrows():\n",
    "    \n",
    "    try:\n",
    "        bboxes = process_bboxes(row['bbox'], row['height'], row['width'])\n",
    "    except:\n",
    "        cleaned_bbox = row['bbox'].replace('[', '').replace(']', '')\n",
    "\n",
    "    new_row = {\n",
    "        'image_path': row['image_path'],\n",
    "        'patient_id': row['patient_id'],\n",
    "        'numfind': row['numfind'],\n",
    "        'bbox': bboxes,\n",
    "        'height': row['height'],\n",
    "        'width': row['width'],\n",
    "        # 'label': row['label']\n",
    "    }\n",
    "\n",
    "    embdata_df.loc[len(embdata_df)] = new_row\n",
    "\n",
    "\n",
    "for _, row in vindr_with_finds.iterrows():\n",
    "    \n",
    "    try:\n",
    "        bboxes = process_bboxes(str(row['bbox']), row['height'], row['width'], embed=False)\n",
    "    except:\n",
    "        bboxes = process_bboxes(str([row['bbox']]), row['height'], row['width'], embed=False)\n",
    "\n",
    "    new_row = {\n",
    "        'image_path': row['image_path'],\n",
    "        'patient_id': row['patient_id'],\n",
    "        'numfind': row['numfind'],\n",
    "        'bbox': bboxes,\n",
    "        'height': row['height'],\n",
    "        'width': row['width'],\n",
    "        # 'label': row['label'],\n",
    "    }\n",
    "\n",
    "    vindr_df.loc[len(vindr_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3471067/2106613283.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_finds['image_path'] = str(EMBED_ROOT) + '/' + 'images/png/1024x768/' + df_no_finds['image_path']\n",
      "/tmp/ipykernel_3471067/2106613283.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vindr_no_finds['image_path'] = str(VINDR_ROOT) + '/' + 'pngs/' + vindr_no_finds['image_path']\n"
     ]
    }
   ],
   "source": [
    "df_no_finds['image_path'] = str(EMBED_ROOT) + '/' + 'images/png/1024x768/' + df_no_finds['image_path']\n",
    "embdata_df['image_path'] = str(EMBED_ROOT) + '/' + 'images/png/1024x768/' + embdata_df['image_path']\n",
    "vindr_no_finds['image_path'] = str(VINDR_ROOT) + '/' + 'pngs/' + vindr_no_finds['image_path']\n",
    "vindr_df['image_path'] = str(VINDR_ROOT) + '/' + 'pngs/' + vindr_df['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to ensure numfind value is correct\n",
    "embdata_df['numfind'] = embdata_df['bbox'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this value to desired negative-to-positive sample ratio\n",
    "neg_sam_ratio = 1\n",
    "\n",
    "sampled_embed_df = df_no_finds.sample(n=len(embdata_df)*neg_sam_ratio, random_state=42)\n",
    "sampled_vindr_df = vindr_no_finds.sample(n=len(vindr_df)*neg_sam_ratio, random_state=42)\n",
    "\n",
    "embed_data = pd.concat([sampled_embed_df, embdata_df])\n",
    "vindr_data = pd.concat([sampled_vindr_df, vindr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by patient ID\n",
    "unique_patient_ids_embed = embed_data['patient_id'].unique()\n",
    "unique_patient_ids_vindr = vindr_data['patient_id'].unique()\n",
    "\n",
    "# train = 0.7, val = 0.2, test = 0.1\n",
    "train_ids_embed, val_test_ids_embed = train_test_split(unique_patient_ids_embed, test_size=0.3, random_state=42)\n",
    "val_ids_embed, test_ids_embed = train_test_split(val_test_ids_embed, test_size=0.33)\n",
    "train_ids_vindr, val_test_ids_vindr = train_test_split(unique_patient_ids_vindr, test_size=0.3, random_state=42)\n",
    "val_ids_vindr, test_ids_vindr = train_test_split(val_test_ids_vindr, test_size=0.33)\n",
    "\n",
    "train_embed = embed_data[embed_data['patient_id'].isin(train_ids_embed)]\n",
    "val_embed = embed_data[embed_data['patient_id'].isin(val_ids_embed)]\n",
    "test_embed = embed_data[embed_data['patient_id'].isin(test_ids_embed)]\n",
    "\n",
    "train_vindr = vindr_data[vindr_data['patient_id'].isin(train_ids_vindr)]\n",
    "val_vindr= vindr_data[vindr_data['patient_id'].isin(val_ids_vindr)]\n",
    "test_vindr = vindr_data[vindr_data['patient_id'].isin(test_ids_vindr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv files from our train, val, test dataframes\n",
    "train_embed.to_csv('../retinanet/csv_files/unfiltered_embvind_1:1/train_em.csv', index=False)\n",
    "val_embed.to_csv('../retinanet/csv_files/unfiltered_embvind_1:1/val_em.csv', index=False)\n",
    "test_embed.to_csv('../retinanet/csv_files/unfiltered_embvind_1:1/test_em.csv', index=False)\n",
    "\n",
    "train_vindr.to_csv('../retinanet/csv_files/unfiltered_embvind_1:1/train_em.csv', index=False)\n",
    "val_vindr.to_csv('../retinanet/csv_files/unfiltered_embvind_1:1/val_em.csv', index=False)\n",
    "test_vindr.to_csv('../retinanet/csv_files/unfiltered_embvind_1:1/test_em.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
