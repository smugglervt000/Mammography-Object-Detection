{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import ast\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.io import imread\n",
    "\n",
    "EMBED_ROOT = Path(\"/vol/biomedic3/data/EMBED\")\n",
    "VINDR_ROOT = Path(\"/vol/biomedic3/data/VinDR-Mammo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need instance number for our specific casewise aggregation methodologies\n",
    "dicom = pd.read_csv(\n",
    "    EMBED_ROOT / \"tables/EMBED_OpenData_metadata.csv\", low_memory=False\n",
    ")\n",
    "\n",
    "vindr_findings = pd.read_csv(\n",
    "    VINDR_ROOT / \"finding_annotations.csv\", low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom[\"image_path\"] = (\n",
    "    dicom[\"empi_anon\"].astype(\"str\")\n",
    "    + \"/\"\n",
    "    + dicom[\"anon_dicom_path\"].str.split(\"/\").str[-1].str.split(\".dcm\").str[0]\n",
    "    + \".png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XCCL shouldn't be converted to CC so manually editing it\n",
    "dicom.loc[\n",
    "    (dicom[\"SeriesDescription\"] == \"RXCCL\") | (dicom[\"SeriesDescription\"] == \"LXCCL\"),\n",
    "    \"ViewPosition\",\n",
    "] = \"XCCL\"\n",
    "\n",
    "# Getting all rows with \"ViewPosition\" == Nan (but for which SeriesDescription is also not nan, as these are the ones subject to the data entry error)\n",
    "view_nan = dicom.loc[\n",
    "    (dicom.ViewPosition.isna()) & (dicom.SeriesDescription.isna() == False)\n",
    "]\n",
    "\n",
    "# Drop these rows from\n",
    "dicom_no_nans = dicom[~dicom.index.isin(view_nan.index)]\n",
    "\n",
    "view_nan[\"ViewPosition\"] = view_nan[\"SeriesDescription\"].apply(\n",
    "    lambda x: \"CC\" if \"CC\" in x else (\"MLO\" if \"MLO\" in x else None)\n",
    ")\n",
    "\n",
    "dicom = pd.concat([dicom_no_nans, view_nan], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dicom))\n",
    "# Remove any duplicated images\n",
    "dicom = dicom.drop_duplicates(subset=\"anon_dicom_path\")\n",
    "# Remove spot compressed and magnified images\n",
    "dicom = dicom[dicom.spot_mag.isna()]\n",
    "# Remove invalid views\n",
    "dicom = dicom[dicom.ViewPosition.isin([\"CC\", \"MLO\"])]\n",
    "# Remove images from male clients\n",
    "dicom = dicom[dicom.PatientSex == \"F\"]\n",
    "print(len(dicom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any unnecessary fields from the DICOM imagewise dataframe (this may need to be updated in the future if other fields are deemed relevant)\n",
    "dicom = dicom[\n",
    "    [\n",
    "        \"empi_anon\",\n",
    "        \"acc_anon\",\n",
    "        \"image_path\",\n",
    "        \"FinalImageType\",\n",
    "        \"ImageLateralityFinal\",\n",
    "        \"ViewPosition\",\n",
    "        \"Manufacturer\",\n",
    "        \"ManufacturerModelName\",\n",
    "         'ROI_coords',\n",
    "        'num_roi',\n",
    "        'PatientOrientation',\n",
    "        \"Rows\",\n",
    "        \"Columns\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "vindr_findings = vindr_findings[\n",
    "    [\n",
    "        'study_id',\n",
    "        'image_id',\n",
    "        'height',\n",
    "        'width',\n",
    "        'breast_birads',\n",
    "        'breast_density',\n",
    "        'finding_categories',\n",
    "        'finding_birads',\n",
    "        'xmin',\n",
    "        'ymin',\n",
    "        'xmax',\n",
    "        'ymax'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'xmin', 'ymin', 'xmax', 'ymax' \n",
    "vindr_findings['bbox'] = vindr_findings.apply(lambda row: [row['ymin'], row['xmin'], row['ymax'], row['xmax']], axis=1)\n",
    "\n",
    "# Drop the individual columns 'xmin', 'ymin', 'xmax', 'ymax'\n",
    "vindr_findings.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1, inplace=True)\n",
    "\n",
    "# Remove findings with a birads recorded as None\n",
    "filtered_vindr = vindr_findings[(vindr_findings['finding_birads'].notna()) | (vindr_findings['finding_categories'].apply(lambda x: x == \"['No Finding']\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = filtered_vindr[filtered_vindr.duplicated(subset=['study_id', 'image_id'], keep=False)]\n",
    "\n",
    "# Function to aggregate the relevant columns\n",
    "def aggregate_columns(group):\n",
    "    agg_dict = {}\n",
    "    for col in ['finding_categories', 'finding_birads']:\n",
    "        agg_dict[col] = group[col].apply(lambda x: [x] if not isinstance(x, list) else x).sum()\n",
    "    # For 'bbox', ensure it is a list of lists\n",
    "    agg_dict['bbox'] = group['bbox'].apply(lambda x: [x] if not isinstance(x, list) else x).tolist()\n",
    "    # Include all other columns, taking the first value \n",
    "    for col in group.columns:\n",
    "        if col not in agg_dict and col not in ['study_id', 'image_id']:\n",
    "            agg_dict[col] = group[col].iloc[0]\n",
    "    agg_dict['image_path'] = group['study_id'].iloc[0] + '/' + group['image_id'].iloc[0] + '.png'\n",
    "    return pd.Series(agg_dict)\n",
    "\n",
    "# Group duplicate rows by 'study_id' and 'image_id' and apply the aggregation function\n",
    "collapsed_duplicates = duplicate_rows.groupby(['study_id', 'image_id']).apply(aggregate_columns).reset_index(drop=True)\n",
    "\n",
    "# Find non-duplicate rows\n",
    "non_duplicate_rows = filtered_vindr[~filtered_vindr.duplicated(subset=['study_id', 'image_id'], keep=False)].copy()\n",
    "\n",
    "# Add 'image_path' to non-duplicate rows \n",
    "non_duplicate_rows.loc[:, 'image_path'] = non_duplicate_rows.apply(lambda row: row['study_id'] + '/' + row['image_id'] + '.png', axis=1)\n",
    "\n",
    "# Remove 'study_id' and 'image_id' columns \n",
    "non_duplicate_rows = non_duplicate_rows.drop(columns=['study_id', 'image_id'])\n",
    "\n",
    "# Combine collapsed duplicates with non-duplicate rows\n",
    "vindr_final = pd.concat([collapsed_duplicates, non_duplicate_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionary to standardised naming of various fields in clincial metadata\n",
    "\n",
    "# Human reader BIRADS density assessment\n",
    "dens_conversion = {1.0: \"A\", 2.0: \"B\", 3.0: \"C\", 4.0: \"D\"}\n",
    "# Load in the clinical metadata\n",
    "mag = pd.read_csv(EMBED_ROOT / \"tables/EMBED_OpenData_clinical.csv\", low_memory=False)\n",
    "print(len(mag))\n",
    "# Remove cases from cases a valid BIRADS density assessment\n",
    "mag = mag[mag.tissueden.isin([1.0, 2.0, 3.0, 4.0])]\n",
    "mag.replace({\"tissueden\": dens_conversion}, inplace=True)\n",
    "# Keep important study metadata tags to join up with final aggregated dataframe at end of script\n",
    "mag = mag[[\"empi_anon\", \"tissueden\", \"study_date_anon\", \"acc_anon\"]].drop_duplicates(\n",
    "    subset=\"acc_anon\"\n",
    ")\n",
    "print(len(mag))\n",
    "# Convert to pandas datetime object\n",
    "mag[\"study_date_anon\"] = pd.to_datetime(mag[\"study_date_anon\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider studies which have a valid link between the DICOM and clinical metadata\n",
    "print(len(dicom))\n",
    "df = mag.merge(dicom, on=\"acc_anon\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vindr_final['finding_categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_flip_bounding_box(orig_coords, orig_height, orig_width, new_height, new_width, flip_horizontal = False, flip_vertical = False):\n",
    "    \"\"\"\n",
    "    Transform bounding box coords to fit on the rescaled DICOM image. \n",
    "\n",
    "    Bounding box outputs are returned in form [y1, x1, y2, x2], where [y1, x1] is at the top left\n",
    "    (ie y1 < y2, and x1 < x2) of image.\n",
    "\n",
    "    \"\"\"\n",
    "    height_decrease = new_height / orig_height\n",
    "    width_decrease = new_width / orig_width\n",
    "\n",
    "    scale_factor = min(height_decrease, width_decrease)\n",
    "\n",
    "    # Rescale the box to be relative to full size image.\n",
    "    coords = (orig_coords * scale_factor).astype(\"int\").tolist()\n",
    "    y1, x1, y2, x2 = coords\n",
    "    # Reflect bbox co-ords based on horizontal or vertical flipping from original patient orientation\n",
    "    # (Remember indexing starts from 0, so subtract 1 from geometric lengths).\n",
    "    # Assume output transformation co-ords identical to original, and apply each separately\n",
    "    y1_new, x1_new, y2_new, x2_new = coords\n",
    "    # Single reflection will yield (y1 > y2) & (x1 > x2), scale by bbox width to get top-left and bottom-right coords\n",
    "    bbox_width = abs(x2 - x1)\n",
    "    if flip_horizontal:\n",
    "        x1_new = new_width - 1 - x1 - bbox_width\n",
    "        x2_new = new_width - 1 - x2 + bbox_width\n",
    "    if flip_vertical:\n",
    "        y1_new = new_height - 1 - y1 - bbox_width\n",
    "        y2_new = new_height - 1 - y2 + bbox_width\n",
    "\n",
    "    return y1_new, x1_new, y2_new, x2_new\n",
    "\n",
    "def convert_str_bbox_to_numpy(coords, embed=True):\n",
    "    if embed:\n",
    "        return np.array(ast.literal_eval(coords.replace('(', '[').replace(')', ']').replace(' ','')))\n",
    "    else:\n",
    "        return np.array(ast.literal_eval(coords.replace(' ','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height = 1024\n",
    "new_width = 768\n",
    "\n",
    "\n",
    "# Take a small subset\n",
    "head = df.loc[df.num_roi > 0].head(30)\n",
    "\n",
    "f, ax = plt.subplots(5,6,figsize=(20,20))\n",
    "ax = ax.ravel()\n",
    "# Iterate over several rows\n",
    "for p, (_, row_df) in enumerate(head.iterrows()):\n",
    "    \n",
    "    # Get original height and width from the csv\n",
    "    orig_height = row_df[\"Rows\"]\n",
    "    orig_width = row_df[\"Columns\"]\n",
    "    \n",
    "    # Convert the string bbox to an array\n",
    "    bboxes = convert_str_bbox_to_numpy(row_df['ROI_coords'])\n",
    "    img_path = row_df.image_path\n",
    "\n",
    "    # Plot image\n",
    "    ax[p].imshow(io.imread('/vol/biomedic3/data/EMBED/images/png/1024x768/' + img_path), cmap='grey')\n",
    "    \n",
    "    # Iterate over boxes and plot over image\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        orig_bbox_coordinates = bboxes[i]\n",
    "        \n",
    "        # Extract processed bbox coords, format is [y1, x1, y2, x2]\n",
    "        bbox_coords = scale_and_flip_bounding_box(orig_bbox_coordinates, orig_height, orig_width, new_height, new_width)\n",
    "        \n",
    "        # Convert to bbox format compatible with matplotlib\n",
    "        y0, x0 = bbox_coords[0], bbox_coords[1]\n",
    "        width = bbox_coords[2] - bbox_coords[0]\n",
    "        h = bbox_coords[3] - bbox_coords[1]\n",
    "        \n",
    "        # Plot\n",
    "        rect = patches.Rectangle((x0, y0), width, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax[p].add_patch(rect)\n",
    "        ax[p].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height = 1024\n",
    "new_width = 768\n",
    "\n",
    "\n",
    "# Take a small subset\n",
    "head = vindr_final.loc[vindr_final.finding_categories != \"['No Finding']\"].head(30)\n",
    "\n",
    "f, ax = plt.subplots(5,6,figsize=(20,20))\n",
    "ax = ax.ravel()\n",
    "# Iterate over several rows\n",
    "for p, (_, row_df) in enumerate(head.iterrows()):\n",
    "    \n",
    "    # Get original height and width from the csv\n",
    "    orig_height = row_df[\"height\"]\n",
    "    orig_width = row_df[\"width\"]\n",
    "    \n",
    "    # Convert the string bbox to an array\n",
    "    bboxes = convert_str_bbox_to_numpy(str(row_df['bbox']), embed=False)\n",
    "    img_path = row_df.image_path\n",
    "\n",
    "    # Rescale image\n",
    "    image = io.imread('/vol/biomedic3/data/VinDR-Mammo/pngs/' + img_path)\n",
    "    image = resize(image, (1024, 768), preserve_range=True)\n",
    "\n",
    "    # Plot image\n",
    "    ax[p].imshow(image, cmap='grey') # ax[p].imshow(io.imread('/vol/biomedic3/data/VinDR-Mammo/pngs/' + img_path), cmap='grey')\n",
    "    \n",
    "    # Iterate over boxes and plot over image\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        orig_bbox_coordinates = bboxes[i]\n",
    "        \n",
    "        # Extract processed bbox coords, format is [y1, x1, y2, x2]\n",
    "        bbox_coords = scale_and_flip_bounding_box(orig_bbox_coordinates, orig_height, orig_width, new_height, new_width)\n",
    "        \n",
    "        # Convert to bbox format compatible with matplotlib\n",
    "        y0, x0 = bbox_coords[0], bbox_coords[1]\n",
    "        width = bbox_coords[2] - bbox_coords[0]\n",
    "        h = bbox_coords[3] - bbox_coords[1]\n",
    "        \n",
    "        # Plot\n",
    "        rect = patches.Rectangle((x0, y0), width, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax[p].add_patch(rect)\n",
    "        ax[p].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
