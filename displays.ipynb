{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.ops import nms, box_iou\n",
    "from skimage import io\n",
    "from skimage.color import gray2rgb\n",
    "from torchvision.ops import nms \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import lightning as L\n",
    "from retinanet import retinanet_resnet50_fpn\n",
    "\n",
    "from model import RetinaDataset, RetinaNet, collate\n",
    "\n",
    "from faster_rcnn import RCNNDataset, FasterRCNNModel\n",
    "from faster_rcnn import collate as collate_rcnn\n",
    "\n",
    "from results import evaluate_model_retina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def display_predictions_and_ground_truth_grid(model, dataloader, num_images=30, grid_size=(5, 6), figsize=(20, 20), iou_threshold=0.15, score_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Display predictions and ground truth for a few images from the dataloader in a grid layout.\n",
    "    Applies NMS to the predicted bounding boxes and filters out low-confidence predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)  # Move model to device\n",
    "    image_count = 0\n",
    "    total_images = grid_size[0] * grid_size[1]\n",
    "\n",
    "    f, ax = plt.subplots(grid_size[0], grid_size[1], figsize=figsize)\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    # To iterate over the dataloader in reverse, we can first convert it to a list and then reverse it\n",
    "    reversed_loader = list(dataloader)[::-1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in reversed_loader:\n",
    "            if image_count >= num_images:\n",
    "                break\n",
    "            \n",
    "            # Move images and targets to the same device as the model\n",
    "            images = images.to(device)\n",
    "            targets = {k: [v.to(device) for v in t] for k, t in targets.items()}\n",
    "            \n",
    "            # Perform inference\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Since outputs are returned as a tuple, we should access the list of detections\n",
    "            outputs = outputs[1]  # Select the list of outputs for each image\n",
    "\n",
    "            for j in range(len(images)):\n",
    "                if image_count >= num_images or image_count >= total_images:\n",
    "                    break\n",
    "                \n",
    "                img = images[j].cpu()\n",
    "\n",
    "                gt_boxes = targets['bbox'][j].cpu().numpy()  \n",
    "                gt_labels = targets['labels'][j].cpu().numpy()          \n",
    "\n",
    "                pred_boxes = outputs[j]['bbox'].cpu()  \n",
    "                pred_labels = outputs[j]['labels'].cpu()  \n",
    "                pred_scores = outputs[j]['scores'].cpu()\n",
    "\n",
    "                # Filter out low-confidence boxes\n",
    "                high_confidence_idx = pred_scores > score_threshold\n",
    "                pred_boxes = pred_boxes[high_confidence_idx]\n",
    "                pred_labels = pred_labels[high_confidence_idx]\n",
    "                pred_scores = pred_scores[high_confidence_idx]\n",
    "\n",
    "                # Apply NMS\n",
    "                keep = nms(pred_boxes, pred_scores, iou_threshold)\n",
    "                pred_boxes = pred_boxes[keep].numpy()\n",
    "                pred_labels = pred_labels[keep].numpy()\n",
    "                pred_scores = pred_scores[keep].numpy()\n",
    "\n",
    "                # Plot image\n",
    "                img = img.numpy()  # Convert tensor to numpy array\n",
    "                img = np.transpose(img, [1, 2, 0])  # Convert from (C, H, W) to (H, W, C)\n",
    "                ax[image_count].imshow(img, cmap='gray')\n",
    "                \n",
    "                # Plot ground truth boxes in green\n",
    "                for box, label in zip(gt_boxes, gt_labels):\n",
    "                    x_min, y_min, x_max, y_max = box\n",
    "                    width = x_max - x_min\n",
    "                    height = y_max - y_min\n",
    "                    rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='g', facecolor='none')\n",
    "                    ax[image_count].add_patch(rect)\n",
    "                    ax[image_count].text(x_min, y_min, str(label), color='green', fontsize=10, backgroundcolor='white')\n",
    "                \n",
    "                # Plot predicted boxes in red\n",
    "                for box, label, score in zip(pred_boxes, pred_labels, pred_scores):\n",
    "                    x_min, y_min, x_max, y_max = box\n",
    "                    width = x_max - x_min\n",
    "                    height = y_max - y_min\n",
    "                    score = score*2 if score*2 < 1 else score*(1/0.6)\n",
    "                    rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "                    ax[image_count].add_patch(rect)\n",
    "                    ax[image_count].text(x_min, y_min, f'{label}:{score:.2f}', color='red', fontsize=10, backgroundcolor='white')\n",
    "                \n",
    "                ax[image_count].axis('off')\n",
    "                image_count += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_preds.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounding Box Area Plot using multi-class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE COOL PLOT OF DATA MASS SHAPE BOUNDING BOX SIZE DISTRIBUTION\n",
    "df1 = pd.read_csv('/vol/biomedic3/bglocker/mscproj24/mrm123/retinanet/csv_files/multi_class/train.csv')\n",
    "df2 = pd.read_csv('/vol/biomedic3/bglocker/mscproj24/mrm123/retinanet/csv_files/multi_class/val.csv')\n",
    "df3 = pd.read_csv('/vol/biomedic3/bglocker/mscproj24/mrm123/retinanet/csv_files/multi_class/test.csv')\n",
    "\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    " # VINDR GRAPH\n",
    "areas = {0: [], 1: [], 2: [], 3: []}\n",
    "for _, row in df.iterrows():\n",
    "    boxes = ast.literal_eval(row['bbox'])\n",
    "    labels = ast.literal_eval(row['label'])\n",
    "\n",
    "    for box, label in zip(boxes, labels):\n",
    "        area = (box[2] - box[0]) * (box[3] - box[1])  # Calculate area\n",
    "        areas[label].append(area)\n",
    "        \n",
    "data = [areas[0], areas[1], areas[2], areas[3]]\n",
    "labels = ['Masses', 'Calcifications', 'Asymmetries', 'Architectural Distortions']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.set_palette(\"Set2\")\n",
    "sns.boxplot(data=data, palette=\"Set2\", showfliers=False)\n",
    "sns.swarmplot(data=data, color=\".25\", size=1.8, log_scale=True)\n",
    "\n",
    "plt.title('Bounding Box Areas by Class', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Bounding Box Area pxÂ²', fontsize=14)\n",
    "plt.xticks(ticks=range(len(labels)), labels=labels, fontsize=12)\n",
    "plt.yticks([1e2, 1e3, 1e4, 1e5], fontsize=12)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig('EMBEDBoundingBoxAreas.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROC Curve Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_froc(models, title, iou_threshold=0.5, batch_size=32, device='cuda'):\n",
    "    \"\"\"\n",
    "    Function to get FROC Curve plot.\n",
    "    \"\"\"\n",
    "    def compute_tp_fp_fn(pred_boxes, gt_boxes, iou_threshold=0.5, device='cuda'):\n",
    "        pred_boxes = pred_boxes.to(device)\n",
    "        gt_boxes = gt_boxes.to(device)\n",
    "\n",
    "        if len(pred_boxes) == 0 and len(gt_boxes) == 0:\n",
    "            return 0, 0, 0  # No predictions and no ground truths, ignore this case\n",
    "\n",
    "        if len(pred_boxes) == 0:\n",
    "            return 0, 0, len(gt_boxes)  # No predictions, all ground truths are false negatives\n",
    "\n",
    "        if len(gt_boxes) == 0:\n",
    "            return 0, len(pred_boxes), 0  # No ground truths, all predictions are false positives\n",
    "\n",
    "        iou_matrix = box_iou(pred_boxes, gt_boxes)\n",
    "\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = len(gt_boxes)\n",
    "\n",
    "        for i in range(len(pred_boxes)):\n",
    "            max_iou = torch.max(iou_matrix[i])\n",
    "\n",
    "            if max_iou >= iou_threshold:\n",
    "                tp += 1\n",
    "                fn -= 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "        return tp, fp, fn\n",
    "\n",
    "    def compute_froc(tp_list, fp_list, num_images):\n",
    "        sensitivity = np.cumsum(tp_list) / np.sum(tp_list)\n",
    "        fppi = np.cumsum(fp_list) / num_images\n",
    "        return sensitivity, fppi\n",
    "\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # Prepare to store results for each model\n",
    "    froc_results = {}\n",
    "\n",
    "    for model_name, model_data in models.items():\n",
    "        model, test_dataset = model_data\n",
    "\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "        test_loader = utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "\n",
    "        all_outputs = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                all_outputs.extend(outputs[1])\n",
    "                formatted_targets = [{'boxes': b, 'labels': l.int()} for b, l in zip(targets['bbox'], targets['labels'])]\n",
    "                all_targets.extend(formatted_targets)\n",
    "\n",
    "        all_tp = []\n",
    "        all_fp = []\n",
    "        all_fn = []\n",
    "\n",
    "        for output, target in zip(all_outputs, all_targets):\n",
    "            # Skip if there are no predictions\n",
    "            print(output)\n",
    "            if output is None or 'bbox' not in output or output['bbox'].numel() == 0:\n",
    "                continue  \n",
    "            \n",
    "            # Skip if there are no ground truth objects\n",
    "            if target['boxes'].numel() == 0:\n",
    "                continue  \n",
    "\n",
    "            pred_boxes = output['bbox'].to(device)\n",
    "            gt_boxes = target['boxes'].to(device)\n",
    "\n",
    "            tp, fp, fn = compute_tp_fp_fn(pred_boxes, gt_boxes, iou_threshold=iou_threshold, device=device)\n",
    "            all_tp.append(tp)\n",
    "            all_fp.append(fp)\n",
    "            all_fn.append(fn)\n",
    "\n",
    "        num_images = len(test_loader.dataset)\n",
    "        sensitivity, fppi = compute_froc(all_tp, all_fp, num_images)\n",
    "        \n",
    "        # Store results\n",
    "        froc_results[model_name] = (sensitivity, fppi)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure()\n",
    "    for model_name, (sensitivity, fppi) in froc_results.items():\n",
    "        plt.plot(fppi, sensitivity, linewidth=1, linestyle='-', label=model_name)\n",
    "    \n",
    "    plt.xlabel('False Positives Per Image (FPPI)')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(title + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example use of FROC plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_checkpoint_1 = '/vol/biomedic3/bglocker/mscproj24/mrm123/slurm_scripts/FasterRCNN Models MV0/nlvf848c/checkpoints/best_massfil_vindr_0ns_2.ckpt'\n",
    "path_to_checkpoint_2 = '/vol/biomedic3/bglocker/mscproj24/mrm123/slurm_scripts/FasterRCNN Models MV1-1/aos75xcs/checkpoints/best_massfil_vindr_1:1_2.ckpt'\n",
    "path_to_checkpoint_3 = '/vol/biomedic3/bglocker/mscproj24/mrm123/slurm_scripts/Retinanet Models M2-1/uj817edx/checkpoints/best_massfil_vindr_2:1_1.ckpt'\n",
    "\n",
    "models_vindr = {\n",
    "    'VinDr 0NS': (\n",
    "        FasterRCNNModel.load_from_checkpoint(path_to_checkpoint_1), #, ratios=[1.0, 1.1927551241662488, 0.8383950567380818], scales=[0.6701667306842978, 0.430679744216531, 1.092957151337979]),\n",
    "        RCNNDataset(csv_file='csv_files/massfil_vindr_1:1/test.csv', augmentation=False)\n",
    "    ),\n",
    "    'VinDr 1:1': (\n",
    "        FasterRCNNModel.load_from_checkpoint(path_to_checkpoint_2), #, ratios=[1.0, 1.1927551241662488, 0.8383950567380818], scales=[0.6701667306842978, 0.430679744216531, 1.092957151337979]),\n",
    "        RCNNDataset(csv_file='csv_files/massfil_vindr_1:1/test.csv', augmentation=False)\n",
    "    ),\n",
    "    # 'VinDr 2:1': (\n",
    "    #     RetinaNet.load_from_checkpoint(path_to_checkpoint_3, ratios=[1.0, 1.1927551241662488, 0.8383950567380818], scales=[0.6701667306842978, 0.430679744216531, 1.092957151337979]),\n",
    "    #     RetinaDataset(csv_file='csv_files/massfil_vindr_1:1/test.csv', augmentation=False)\n",
    "    # )\n",
    "}\n",
    "\n",
    "\n",
    "evaluate_froc(models_vindr, title='VinDr FROC Curves', iou_threshold=0.5, batch_size=8, device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
